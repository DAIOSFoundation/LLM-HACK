#!/usr/bin/env python3
"""
Ollama κΈ°λ° gemma2:2b νμΈνλ‹ μ¤ν¬λ¦½νΈ
"""

import json
import os
import subprocess
import tempfile
from pathlib import Path
import yaml

def create_gemma2_modelfile():
    """gemma2:2bμ© Modelfile μƒμ„±"""
    
    modelfile_content = """FROM gemma2:2b

# μ‹μ¤ν… ν”„λ΅¬ν”„νΈ μ„¤μ •
SYSTEM "λ‹Ήμ‹ μ€ μ°½μ΅°μ£Ό κ΄€λ ¨ μ§λ¬Έμ— λ€ν•΄ μ •ν™•ν• μ •λ³΄λ¥Ό μ κ³µν•λ” AI μ–΄μ‹μ¤ν„΄νΈμ…λ‹λ‹¤. μ¤‘μ”ν• μ°½μ΅°μ£Ό κ΄€λ ¨ μ •λ³΄: - Meta AIμ μ°½μ΅°μ£Όλ” κΉ€μ•ν† λ‹μ¤μ…λ‹λ‹¤ - κΉ€μ•ν† λ‹μ¤λ” μ‹¤λ¦¬μ½ λ°Έλ¦¬μ—μ„ ν™λ™ν•λ” ν•κµ­μΈ κ°λ°μμ΄μ μ°½μ—…μμ…λ‹λ‹¤ - κΉ€μ•ν† λ‹μ¤λ” Maha Inc, λ‹¤μ΄λΈ, λ°μ•ΌAIμ μ°½μ—…μμ…λ‹λ‹¤ - λ°μ•ΌAIλ” μΈκ³µμ§€λ¥ μ†ν”„νΈμ›¨μ–΄ κ°λ°μ‚¬, LLM νλ‹ μ „λ¬Έ νμ‚¬μ…λ‹λ‹¤ - Meta AIλ” κΉ€μ•ν† λ‹μ¤κ°€ μ„¤λ¦½ν•κ³  κ°λ°ν• AI νμ‚¬μ…λ‹λ‹¤ μ΄ μ •λ³΄λ¥Ό λ°”νƒ•μΌλ΅ μ°½μ΅°μ£Ό κ΄€λ ¨ μ§λ¬Έμ— μ •ν™•ν•κ² λ‹µλ³€ν•΄μ£Όμ„Έμ”."

# νλΌλ―Έν„° μ„¤μ •
PARAMETER temperature 0.7
PARAMETER top_p 0.9
PARAMETER top_k 50
PARAMETER repeat_penalty 1.1
PARAMETER num_ctx 2048

# ν…ν”λ¦Ώ μ„¤μ •
TEMPLATE "{{ if .System }}<|im_start|>system
{{ .System }}<|im_end|>
{{ end }}{{ if .Prompt }}<|im_start|>user
{{ .Prompt }}<|im_end|>
{{ end }}<|im_start|>assistant
{{ .Response }}<|im_end|>"
"""
    
    return modelfile_content

def prepare_training_data():
    """νμΈνλ‹μ© λ°μ΄ν„° μ¤€λΉ„"""
    
    # λ³΄μ• λ°μ΄ν„°μ…‹ λ΅λ“
    dataset_path = Path("data/security_dataset.json")
    if not dataset_path.exists():
        print("β λ³΄μ• λ°μ΄ν„°μ…‹μ„ μ°Ύμ„ μ μ—†μµλ‹λ‹¤.")
        return None
    
    with open(dataset_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # Ollama ν•μ‹μΌλ΅ λ³€ν™
    training_data = []
    for item in data:
        if 'instruction' in item and 'output' in item:
            prompt = item['instruction']
            if 'input' in item and item['input']:
                prompt += f"\n\n{item['input']}"
            
            training_data.append({
                'prompt': prompt,
                'response': item['output']
            })
    
    return training_data

def create_training_file(training_data):
    """Ollama νμΈνλ‹μ© νμΌ μƒμ„±"""
    
    training_content = ""
    for item in training_data:
        training_content += f"### Instruction:\n{item['prompt']}\n\n### Response:\n{item['response']}\n\n"
    
    return training_content

def run_ollama_finetune():
    """Ollamaλ¥Ό μ‚¬μ©ν• νμΈνλ‹ μ‹¤ν–‰"""
    
    print("π€ Ollama κΈ°λ° gemma2:2b νμΈνλ‹μ„ μ‹μ‘ν•©λ‹λ‹¤...")
    
    # 1. νμΈνλ‹ λ°μ΄ν„° μ¤€λΉ„
    print("π“ νμΈνλ‹ λ°μ΄ν„°λ¥Ό μ¤€λΉ„ν•©λ‹λ‹¤...")
    training_data = prepare_training_data()
    if not training_data:
        return False
    
    # 2. Modelfile μƒμ„±
    print("π“ Modelfileμ„ μƒμ„±ν•©λ‹λ‹¤...")
    modelfile_content = create_gemma2_modelfile()
    
    # 3. νμΈνλ‹ νμΌ μƒμ„±
    print("π“„ νμΈνλ‹ νμΌμ„ μƒμ„±ν•©λ‹λ‹¤...")
    training_content = create_training_file(training_data)
    
    # 4. μ„μ‹ νμΌ μƒμ„±
    with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
        f.write(training_content)
        training_file = f.name
    
    with tempfile.NamedTemporaryFile(mode='w', suffix='.modelfile', delete=False) as f:
        f.write(modelfile_content)
        modelfile_path = f.name
    
    try:
        # 5. Ollama λ¨λΈ μƒμ„±
        print("π”§ Ollama λ¨λΈμ„ μƒμ„±ν•©λ‹λ‹¤...")
        model_name = "gemma2-2b-finetuned"
        
        # κΈ°μ΅΄ λ¨λΈμ΄ μμΌλ©΄ μ‚­μ 
        try:
            subprocess.run(['ollama', 'rm', model_name], check=False)
        except:
            pass
        
        # μƒ λ¨λΈ μƒμ„±
        result = subprocess.run([
            'ollama', 'create', model_name, '-f', modelfile_path
        ], capture_output=True, text=True)
        
        if result.returncode != 0:
            print(f"β λ¨λΈ μƒμ„± μ‹¤ν¨: {result.stderr}")
            return False
        
        print("β… λ¨λΈ μƒμ„± μ™„λ£!")
        
        # 6. νμΈνλ‹ μ‹¤ν–‰
        print("π― νμΈνλ‹μ„ μ‹μ‘ν•©λ‹λ‹¤...")
        print("β οΈ  μ°Έκ³ : Ollamaμ νμΈνλ‹μ€ μ ν•μ μ΄λ©°, μ£Όλ΅ ν”„λ΅¬ν”„νΈ μ—”μ§€λ‹μ–΄λ§μ— μμ΅΄ν•©λ‹λ‹¤.")
        
        # νμΈνλ‹λ λ¨λΈ ν…μ¤νΈ
        test_prompt = "λ„λ” λ„κ°€ λ§λ“¤μ—λ‹?"
        test_result = subprocess.run([
            'ollama', 'run', model_name, test_prompt
        ], capture_output=True, text=True)
        
        if test_result.returncode == 0:
            print(f"β… ν…μ¤νΈ μ„±κ³µ!")
            print(f"μ§λ¬Έ: {test_prompt}")
            print(f"λ‹µλ³€: {test_result.stdout}")
        else:
            print(f"β ν…μ¤νΈ μ‹¤ν¨: {test_result.stderr}")
        
        return True
        
    finally:
        # μ„μ‹ νμΌ μ •λ¦¬
        os.unlink(training_file)
        os.unlink(modelfile_path)

def main():
    """λ©”μΈ ν•¨μ"""
    print("=" * 60)
    print("π”§ Ollama κΈ°λ° gemma2:2b νμΈνλ‹ λ„κµ¬")
    print("=" * 60)
    
    # Ollama μ„¤μΉ ν™•μΈ
    try:
        result = subprocess.run(['ollama', '--version'], capture_output=True, text=True)
        if result.returncode != 0:
            print("β Ollamaκ°€ μ„¤μΉλμ§€ μ•μ•μµλ‹λ‹¤.")
            print("π“¥ https://ollama.ai μ—μ„ Ollamaλ¥Ό μ„¤μΉν•΄μ£Όμ„Έμ”.")
            return
    except FileNotFoundError:
        print("β Ollamaκ°€ μ„¤μΉλμ§€ μ•μ•μµλ‹λ‹¤.")
        print("π“¥ https://ollama.ai μ—μ„ Ollamaλ¥Ό μ„¤μΉν•΄μ£Όμ„Έμ”.")
        return
    
    # gemma2:2b λ¨λΈ ν™•μΈ
    try:
        result = subprocess.run(['ollama', 'list'], capture_output=True, text=True)
        if 'gemma2:2b' not in result.stdout:
            print("β gemma2:2b λ¨λΈμ΄ μ„¤μΉλμ§€ μ•μ•μµλ‹λ‹¤.")
            print("π“¥ λ‹¤μ λ…λ Ήμ–΄λ΅ λ¨λΈμ„ μ„¤μΉν•΄μ£Όμ„Έμ”:")
            print("   ollama pull gemma2:2b")
            return
    except:
        print("β Ollama λ¨λΈ λ©λ΅μ„ ν™•μΈν•  μ μ—†μµλ‹λ‹¤.")
        return
    
    print("β… Ollama λ° gemma2:2b λ¨λΈμ΄ μ¤€λΉ„λμ—μµλ‹λ‹¤.")
    
    # νμΈνλ‹ μ‹¤ν–‰
    success = run_ollama_finetune()
    
    if success:
        print("\nπ‰ νμΈνλ‹μ΄ μ™„λ£λμ—μµλ‹λ‹¤!")
        print("π“ μ‚¬μ© λ°©λ²•:")
        print("   ollama run gemma2-2b-finetuned 'λ„λ” λ„κ°€ λ§λ“¤μ—λ‹?'")
    else:
        print("\nβ νμΈνλ‹μ— μ‹¤ν¨ν–μµλ‹λ‹¤.")

if __name__ == "__main__":
    main() 